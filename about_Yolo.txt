==============================================================================================================================
YOLO - You Only Look Once
빠른속도의 Object Detection Neural Network 
==============================================================================================================================


==============================================================================================================================
Yolo Model

Model: 테두리상자(Bounding Box)와 분류(Classification)를 동일 신경망 구조를 통하여 동시에 실행한다. 
Work-Flow:
  1. 입력된 이미지의 영역 전체를  S x S의 그리드로 분할한다. (논문에서 제시한 S의 크기는 7)
  2. 입력된 이미지 전체를 신경망에 넣고 특징 추출을 한다. 
  3. 추출된 특징을 바탕으로 예측 텐서를 생선한다. (Prediction Tensor) = (Each GridBox's 정보, 신뢰점수, 분류된 클래스 확률)
  4. 그리드별 예측정보를 바탕으로 테두리 상자를 조정, 예측 객체 분류 작업을 수행
  5. 각각의 그리드 영역은 n개의 Bounding Box와 해당 Bounding Box에 Confidence-Score를 갖는다. (Confidence-Score = Pr(Object) *IOU)
  6. 각각의 그리드 영역은 m개의 Conditional Class Probability를 갖는다. 
  7. 각각의 Bounding Box는 x, y, w, h, confidence를 갖는다. 
==============================================================================================================================
 
 
==============================================================================================================================
Yolov1 Network

1. 기존의 디텍션 : Single Window나 Regional Proposal Methods 등을 통하여 바운딩 박스를 만들고 
                바운딩 박스에 대해 분류를 수행하는 2개의 Stage Detection으로 완료하는 알고리즘을 통해 진행.
                -> Pipline이 복잡해짐에 따른 학습과 예측이 느려지고 최적화도 느려진다. 
2. Yolov1 : Image detection과는 다르게 하나의 합성곱 네트워크를 통하여 대상의 위치와 클래스를 한번에 예측한다. 

==============================================================================================================================


Yolov5 Architecture
==============================================================================================================================
 What is Backbone Network in Deeplearning
  Backbone은 등뼈라는 의미로, 뇌와 몸의 각 부위를 이어주는 척추를 의미한다. 다양한 Network를 상호 연결하는 컴퓨터 네트워크의 일부다. 
  예를 들어 ResNet같은 경우는 Detection, Segmentation, Pose Estimation, Depth Estimation 등에서 Backbone으로 사용된다.
  즉, 입력정보에 대한 모듈에 대한 처리를 출력으로 보내는 역할이다. (뇌 - 척추 - 팔다리)
  
  
  Backbone => Pre-Train (ImageNet Data) => Classification Network => Features => Detection Network => Fine-tune (Target Data) 
                                                                              => Segmentation
                                                                              => Pose Estimation
                                                                              => Depth Estimation
  
   - backbone은 이미지로부터 Feature Map을 추출하는 부분으로 CSP-Darknet을 사용한다. 
     4가지의 Backbone을 사용한다.
      1) Yolov5s
      2) Yolov5m
      3) Yolov5l
      4) Yolov5x
      
   - Head는 추출된 Feature Map을 바탕으로 물체의 위치를 찾는 부분이다. 
     Anchor Box(Default Box)를 처음에 설정하고, 이를 이용하여 Bounding Box를 생성한다. 
     3가지 Scale의 Bounding Box를 생성한다. (8 Pixel 정보를 가진 작은 물체, 16 Pixel 정보를 가진 중간 물체, 32 Pixel 정보를 가진 큰 물체)
     각 Scale에서는 각각 3개의 Anchor Box를 사용하여 총 9개의 Anchor Box를 사용한다.
==============================================================================================================================
      
==============================================================================================================================
 yolo.py 
  - 욜로 아키텍쳐에 관한 코드. 이 파일을 이용하여 Yolo Architecture가 생성된다. 
 common.py
  - yolo Architecture를 구성하는 모듈(Layer)에 관한 코드이며 conv, BottleckCSP등 yolo 모듈이 정의되어 있다.  
============================================================================================================================== 
  
============================================================================================================================== 
 Yolo
============================================================================================================================== 
  
  
  
============================================================================================================================== 
  
 1. Yolo 학습 진행 및 인자 설명 
  ex) python train.py --data coco.yaml --cfg yolov5s.yaml --weight '' --batch-size 64
                         데이터셋 경로, 모델 파일의 경로, 초기화된 파일의 경로, 배치사이즈 입력
  1) --data : data yaml 파일의 경로이다. (Dataset(coco.yaml)의 정보가 적힌 yaml 파일이다.)
  2) --weight : Pre-trained 모델의 파일경로이다. (pt(Model 저장파일)형식이다.)
                아무런 값을 넣지않으면('') 랜덤한 weight 값으로 초기화 및 학습을 진행한다. Github에서는 pre-trained 파일을 사용할것을 추천한다.
                (pre-trained : 학습 파라미터 weight와 bias가 잘 초기화된 파일) => --weight yolov5s.pt를 입력하여 pre-train 모델을 사용한다.
  3) --batch-size : 사용하는 GPU 성능에 맞게 설정하면된다. 
  4) --cfg : yolov5의 아키텍쳐 yaml파일 경로를 입력한다. (yolov5 s, m, l, x 4가지가 존재한다.)
  
 2. 이미지로 테스트 해보기 
  ex) python detect.py --source data/images --weight yolov5s.pt --conf 0.25
      python3 detect.py --source data/images/detection.mp4 --weight yolov5s.pt --cof 0.25
  
  1) --source : 테스트 이미지(또는 폴더) 경로
  2) --weight : 학습이 완료된 weight 파일 경로(pt형식), 1.에서 weight의 경로를 수정하지 않는다면 last.py와 best.py가 저장된다. last.py의 경우 최신 학습의 pt이고
                best.pt는 가장 성능이 좋은 weight 파일이다. 
  3) --conf : conf_threshold 값 (0 ~ 1)
  4) class score가 설정한 값을 넘겨야 Bounding Box를 그릴 수 있다. 
  5)     python3 detect.py --source data/images/detection.mp4 --weight yolov5s.pt --cof 0.25 exp폴더에 생성.
============================================================================================================================== 

============================================================================================================================== 
  Yolov5's Module 
  1. Focus: B, C, W, H의 정보를 변환하는 부분, x(b, c, w, h) -> y(b, 4c, w/2, h/2)로 변환한다. 
            Batchsize, Channel, Width, Height 정보를 변환하여 중점부분을 찾는것으로 보임. 
    class Focus(nn.Module):
      # Focus wh information into c-space
      def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups
          super(Focus, self).__init__()
          self.conv = Conv(c1 * 4, c2, k, s, p, g, act)

      def forward(self, x):  # x(b,c,w,h) -> y(b,4c,w/2,h/2)
          return self.conv(torch.cat([x[..., ::2, ::2], x[..., 1::2, ::2], x[..., ::2, 1::2], x[..., 1::2, 1::2]], 1))
            
  
  2. Conv : 일반적인 Convolution + Batch_Normalize Layer이다. (두개의 연산을 합성하는것은 프로그래밍 스킬로 해석할 수 있다.)
            Conv Layer와 BatchNorm을 합치는 이유는 각각의 수식을 합성하여 하나의 식으로만 사용할 수 있기 때문이다.
            Conv Layer의 Weight값을 Batchnorm의 fused weight로 bias값을 fused bias으로 대체하면 BacthNorm을 생략한채
            Conv Layer 하나로 사용할 수 있다. 
            
            Common.py에서 제시한 Conv 모듈은 Conv2d와 BatchNorm2d 그리고 활성화함수 Hardswish를 갖는다 .
            Conv를 진행 한 후 BatchNorm을 거쳐 Hardswish로 Forward를 진행한다. 
            Hardswish의 경우 swish함수의 변형인데 ReLU를 대체하기 위하여 구글에서 고안한 함수이다. 
            
            **Sigmoid함수에 x를 곱한 간단한 형태인데 Hardswish는 추후에 내용을 보강하겠다.**
            Hardswish Activate Function (Swish = SiLU(Sigmoid Linear Unit)로도 불림)
             - Activate Function의 사용 목적: NN이 어떠한 목적으로 만들었는지에 따라서 선형 함수가 될 수도 있고 복잡도에 따라서 비선형 함수를 학습하기를 바랄 수 있다.
                                             bias를 통한 단순 선형성을 더한다면 복잡한 함수를 만들 수 없어 비교적 복잡도가 높은 비선형 함수를 만들기 위하여 활성화 함수를
                                             사용한다. 
             - swish를 사용하는 이유: 주로 사용하는 ReLU의 경우 y의 값은 음수부터 0까지 값이 '0' 이기 때문에 결국 음수의 범위에서의 미분은 '0'을 갖게 되어 
                                         NN의 Update가 무의미해진다. 이를 방지하고자 LeakyReLU로 대체하기도 하였지만 효과적이지 않다 (실제 검토해볼필요 있음)
                                         반면에 swish 함수의 경우 ReLU에 비하여 조금더 smooth한 그래프를 갖는다. 또한 비 단조함수로써 음수값이 '0'이 되지 않는다.
                                         따라서 음수의 범위에서의 미분에 대한 문제를 해결 할 수 있기 때문에 사용된다. 
             - swish의 특성: 
                            1) sigmoid나 tanh과 같은 함수와 달리 swish는 위로의 경계가 없어 기울기 '0'근처의 값을 갖는 gradient에서 유용하게 동작한다. 
                            2) smooth한 형태를 갖고 있어 최적화(Error검출)에 알맞으며 초기값과 Learning Rate에 덜 민감하다.
                            3) swish는 위로는 상한이 없지만 아래로는 하한이 존재하기 때문에 Regulization에서 좋은 효과를 갖는다. 또한 비 단조함수로 작은 음수에도 
                               음수로 결과를 만들기 때문에 데이터 손실을 줄일 수 있다.
                            4) Selu의 경우 internal normalization이 내포되어 있기 때문에 동일한 장점을 지닌 swish와 비교하여 더 나은 경우도 있을 수 있다.
                            
  3. Bottleneck : CNN의 BottleNeck을 이해하기전 선수 지식이 필요하다. Convolution의 Parameter를 계산할 줄 알아야 하는데 식은 다음과 같다. 
                  ** Convolution Parameter = Kernel Size x Kernel Size x Input Channel x Output Channel
                  BottleNect의 핵심은 1x1 Convolution에 있다. (Pointwise Convolution = Depthwise Separable Convolution)
                  ex1) Convolution Parameter 1 x1 = 1 x 1 x Input Channel x Output Channel 
                       => 1 x 1 Convolution은 연산량이 작지만 Feature Map(Output Channel)의 변화는 크기 때문에 BottleNeck을 사용하여 변화를 준다.
                  
                  ex2) BottleNeck을 활용한 채널의 축소 (Feature Map의 축소) - Example of the difference between Standard and BottleNeck parameters in ResNet 참고
                       (1) Input(B, 256, 320, 320) : B = Batch Size, 256 = InputChannel, 320 x 320 = Output Channel
                       (2) Bottleneck 1 x 1 Convolution, out 64 
                       (3) Input Channel 256 -> Output Channel 64 : 채널이 축소된다. 즉, 채널을 256에서 64로 강제로 축소하여 연산량을 줄인다. 
                       (4) Convolution의 사이즈가 2 x 2 이상 되어야 공간적인 Feature Map이 추출 됨에 따라 1 x 1 사이즈에서는 Spatial(공간적인) 특징은 내포하지 않는다.
                       (5) Bottleneck 3 x 3 Convolution, out 64 : Spatial한 특징(Feature Map)을 내포하는 64개의 Output Channel로 변환한다. 
                       (6) Bottleneck 1 x 1 Convolution, out 256 : Spatial 특징을 제외한 채널을 256으로 증가 시킨다. 
                       (7) (3) ~ (6)의 Bottleneck 구조를 통하여 Convolution Parameter의 값을 줄인다. 단, Parameter의 값이 줄이며 연산량을 최소화 시킬 수 있으나 
                           정보의 손실을 불러일으키기 때문에 모델의 정확도를 떨어트릴 수 있다. 이러한 이유로 연산량과 손실값에 대한 Tradeoff를 적절하게 해주어야 한다.
                           
  4. BottleneckCSP : Yolov5의 핵심이다. DenseNet의 표방하여 만들어 졌다. CSPDarknet 참고필요 
  
  5. DenseNet : Densely Connected Convolutional Network로 ResNet, Pre-Activation ResNet와 비교하여 적은 수의 파라미터로 높은 성능을 갖는다. 
                DenseNet의 특징은 모든 Layer가 처음부터 마지막까지 직렬로 연결되어 있으며 그렇기 때문에 사전 준비되어야하는 점과 기존의 문제를 해결하는 점이 있다.
                1) Convolution Layer의 Feature Map이 다음 Convolution Layer에 직접 전달되기 때문에 Layer 연결 시에 Feature Map의 사이즈를 맞춰야된다.
                2) 이전 Feature Map이 다음 Feature Map에 전달되는 방식으로 처음부터 마지막까지 연결되기 때문에 Gradient Reuse에 대한 문제가 해소된다.(Information Flow)가 
                   향상된다.)
                3) Feature Map을 계속 하여 연결하기 때문에 Channel의 수가 무수하게 많아지는 문제가 있기 때문에 Channel의 수를 굉장히 작은 값을 사용해야한다.
                4) 3)의 이유로 Channel을 적게 사용하기 때문에 Parameter의 수도 줄어들어 연산량이 적어진다. 
                5) Layer 간 연결을 할때 ResNet과 같이 덧셈(Information Flow의 영향으로 지연될 가능성 존재)등의 연산을 하지 않고 단순하게 Concatenate 한다.
                
                  
                  
                                         
            
            
            
            
            
            

  
 
 
 
 
 
 
 
 
 
 
 
 
 
















